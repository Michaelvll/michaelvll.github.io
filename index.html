<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Zhanghao Wu</title>
  <meta name="description" content="Zhanghao Wu's personal website
">

  <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicon.ico">

  <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
  <link rel="canonical" href="http://localhost:4000/">
</head>

<!-- Mathjax Support -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="http://localhost:4000/">About</a>

        <!-- Blog -->
        

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="http://localhost:4000/projects/">Projects</a>
          
        
          
            <a class="page-link" href="http://localhost:4000/publications/">Publications</a>
          
        
          
        

        <!-- CV link -->
        <a class="page-link" href="http://localhost:4000/assets/pdf/cv.pdf">CV</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title"><black>Zhanghao <slim>Wu</slim></black></h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content <black>Zhanghao <slim>Wu</slim></black> clearfix">
    
  <div class="profile col one right">
    
      <img class="one" src="http://localhost:4000/assets/img/my_pic.jpg">
    
    

    
    <div class="address">
        <center>
        
            
            <a href="mailto:zhanghao.wu@outlook.com">Email</a>
        
        
        
             / 
            
            <a href="https://www.github.com/Michaelvll" target="_blank" title="GitHub">GitHub</a>
        
        
        </center>
    </div>
    
  </div>


<p>I am a senior student majoring in <strong>computer science</strong> at <a href="http://en.sjtu.edu.cn">Shanghai Jiao Tong University</a>. I am a member of ACM Honors Class, which is an elite CS program for top 5% talented students. <strong>My overall GPA is 92.13/100, Rank: 2/37</strong>.</p>

<p>Currently, I am a <strong>visiting student</strong> at MIT, working with Prof. <a href="https://songhan.mit.edu">Song Han</a>.</p>

<p>I am interested in <strong>deep learning</strong>, especially <strong>natural language processing</strong>, <strong>speech</strong> and <strong>efficient AI</strong>.
And I plan to pursue a CS Ph.D. that starts in fall, 2020.</p>

<h3 id="research-experience">Research Experience</h3>

<h4 id="hanlab-mit"><a href="https://songhan.mit.edu">HanLab</a>, MIT</h4>

<p>I am a research assistant supervised by Prof. Song Han at HanLab, MIT, from Jul. 2019 to present.</p>
<ul>
  <li>Focusing on privacy preserving and efficient machine learning.</li>
  <li>Working on efficient natural language processing, especially for machine translation. Proposed a novel primitive with higher capacity than the original transformer under mobile settings and submitted to ICLR 2020.</li>
  <li>Designed an efficient privacy-preserving cloud-edge inference method utilizing the linearity of neural networks.</li>
  <li>Won first place in the CVPR’19 Visual Wake Words challenge and third place (first place of all academic groups) in CVPR’19 Low Power Image Recognition Competition.</li>
</ul>

<h4 id="speechlab-sjtu"><a href="https://speechlab.sjtu.edu.cn/">SpeechLab</a>, SJTU</h4>
<p>I am an undergraduate researcher advised by Prof. Yanmin Qian and Prof. Kai Yu in SpeechLab, SJTU, from Jul. 2018 to present.</p>
<ul>
  <li>Focused on Rich Audio Analysis (RAA), analysis and classification of non-text information within human speech.</li>
  <li>Implemented Deep Canonical Correlation Analysis (DCCA) in pytorch and released the code on GitHub.</li>
  <li>Participated in the translation of the book: Reinforcement Learning: An Introduction by Sutton, R.S., Barto, A.G.</li>
  <li>Established a VAE based data augmentation to improve the robustness of speaker verification systems by modelling the patterns of noise and reverberation in the speaker embeddings. It was accepted by Interspeech 2019 (oral).</li>
</ul>

<h3 id="publications">Publications</h3>
<ol class="bibliography"><li>

<div id="Wu2020efficient">
  
    <span class="title"><strong>Efficient Transformer for Mobile Applications</strong></span>
    <span class="author">
      
        
          
            
              <em>Wu, Zhanghao</em>,
            
          
        
      
        
          
            
              
                Liu, Zhijian,
              
            
          
        
      
        
          
            
              
                Lin, Ji,
              
            
          
        
      
        
          
            
              
                Lin, Yujun,
              
            
          
        
      
        
          
            
              
                and Han, Song
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Submitted to ICLR</em>
    
    
      2020
    
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="https://openreview.net/pdf?id=ByeMPlHKPH" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Transformer has become ubiquitous in natural language processing (e.g., machine translation, question answering); however, it requires enormous amount of computations to achieve high performance, which makes it not suitable for real-world mobile applications since mobile phones are tightly constrained by the hardware resources and battery. In this paper, we investigate the mobile setting (under 500M Mult-Adds) for NLP tasks to facilitate the deployment on the edge devices. We present Long-Short Range Attention (LSRA), where some heads specialize in the local context modeling (by convolution) while the others capture the long-distance relationship (by attention). Based on this primitive, we design Mobile Transformer (MBT) that is tailored for the mobile NLP application. Our MBT demonstrates consistent improvement over the transformer on two well-established language tasks: IWSLT 2014 German-English and WMT 2014 English-German. It outperforms the transformer by 0.9 BLEU under 500M Mult-Adds and 1.1 BLEU under 100M Mult-Adds on WMT’14 English-German. Without the costly architecture search that requires more than 250 GPU years, our manually-designed MBT achieves 0.4 higher BLEU than the AutoML-based Evolved Transformer under the extremely efficient mobile setting (i.e., 100M Mult-Adds).</p>
  </span>
  
</div>
</li>
<li>

<div id="Wu:2019vaeda">
  
    <span class="title"><strong>Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification</strong></span>
    <span class="author">
      
        
          
            
              <em>Wu, Zhanghao</em>,
            
          
        
      
        
          
            
              
                Wang, Shuai,
              
            
          
        
      
        
          
            
              
                Qian, Yanmin,
              
            
          
        
      
        
          
            
              
                and Yu, Kai
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Interspeech</em>
    
    
      2019
    
    
        <strong> (Oral)</strong>
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2248.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Domain or environment mismatch between training and testing, such as various noises and channels, is a major challenge for speaker verification. In this paper, a variational autoencoder (VAE) is designed to learn the patterns of speaker embeddings extracted from noisy speech segments, including i-vector and xvector, and generate embeddings with more diversity to improve the robustness of speaker verification systems with probabilistic linear discriminant analysis (PLDA) back-end. The approach is evaluated on the standard NIST SRE 2016 dataset. Compared to manual and generative adversarial network (GAN) based augmentation approaches, the proposed VAE based augmentation achieves a slightly better performance for i-vector on Tagalog and Cantonese with EERs of 15.54% and 7.84%, and a more significant improvement for x-vector on those two languages with EERs of 11.86% and 4.20%.</p>
  </span>
  
</div>
</li>
<li>

<div id="Han:2019rc">
  
    <span class="title"><strong>Real-Time Image Classification with Proxyless Neural Architecture Search and Quantization-Aware Finetuning</strong></span>
    <span class="author">
      
        
          
            
              
                Han, Cai,
              
            
          
        
      
        
          
            
              
                Wang, Tianzhe,
              
            
          
        
      
        
          
            
              <em>Wu, Zhanghao</em>,
            
          
        
      
        
          
            
              
                Wang, Kuan,
              
            
          
        
      
        
          
            
              
                Lin, Ji,
              
            
          
        
      
        
          
            
              
                and Han, Song
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ICCV workshop</em>
    
    
      2019
    
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
  
    [<a href="http://localhost:4000/assets/papers/Real-Time_Image_Classification_iccv19workshop.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>It is challenging to efficiently deploy deep learning models on resource-constrained hardware devices (e.g., mobile and IoT device) with strict efficiency constraints (e.g., latency, energy consumption). We employ Proxyless Neural Architecture Search (ProxylessNAS) to auto design compact and specialized neural network architectures for the target hardware platform. ProxylessNAS makes latency differentiable, so we can optimize not only accuracy but also latency by gradient descent. Such direct optimization saves the search cost by 200x compared to conventional neural architecture search methods. Our work is followed by quantization-aware finetuning to further boost the efficiency. In Low Power Image Recognition Competition, CVPR’19, our solution won the 3rd place on the task of Real-Time Image Classification (online track).</p>
  </span>
  
</div>
</li></ol>

<h3 id="honors--award">Honors &amp; Award</h3>
<ul>
  <li><strong>First place</strong>, CVPR’19 Visual Wake Words challenge, 2019</li>
  <li><strong>Third place</strong>, CVPR’19 Low Power Image Recognition Competition track 1, 2019</li>
  <li><strong>National Scholarship</strong>, (Top 1%) Ministry of Education of P.R. China, 2018</li>
  <li><strong>Fan Hsu-Chi Chancellor’s Scholarship</strong>, (Top 0.1%), Shanghai Jiao Tong University, 2017</li>
  <li><strong>Outstanding Winner</strong>, Mathematical Contest in Modeling (Top 0.5%, international), COMAP, 2017</li>
  <li><strong>Merit Student</strong>, Shanghai Jiao Tong University, 2017</li>
  <li><strong>Zhiyuan Honorary Scholarship</strong>, Shanghai Jiao Tong University, 2016-2018</li>
</ul>

<h3 id="teaching-experience">Teaching Experience</h3>
<ul>
  <li><a href="https://acm.sjtu.edu.cn/wiki/Compiler_2019">Compiler Design and Implementation</a>, teacher assistant, Spring 2019</li>
  <li><a href="https://acm.sjtu.edu.cn/wiki/Programming_2017">C++ Programing (CS512)</a>, teacher assistant, Fall 2017</li>
</ul>


  </article>

  

  

</div>

      </div>
    </div>

    
        <div class="wrapper">
    &copy; Copyright 2019 Zhanghao Wu.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme, modified by Zhanghao Wu.

    
</div>


    

    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="http://localhost:4000/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="http://localhost:4000/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-125868731-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
